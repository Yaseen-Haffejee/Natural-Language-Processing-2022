{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "241271dd-d202-42b6-bd76-19ddbe73e3be",
   "metadata": {},
   "source": [
    "# <center>  COMS4054A/COMS7066A </center>\n",
    "# <center> Natural Language Processing/Technology (NLP) 2022 </center>\n",
    "## <center> Lab Session 1 </center>\n",
    "### <center> 28 July, 2022 </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fcc1a5-6ab7-4b46-a470-415ad414cf3e",
   "metadata": {},
   "source": [
    "## Objectives of this session\n",
    "- Setup your lab/Jupyter Notebook Environment\n",
    "- Learn and practice regular expressions in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bb0f48-de27-4512-9459-6842f3657abe",
   "metadata": {},
   "source": [
    "## Outline\n",
    "- Basic RE in Python\n",
    "- Text Preprocessing using RE (clean up tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b19b13b-6c32-4de9-8b65-ab4aeb4c4028",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "\n",
    "- Go through the document and run all cells.\n",
    "- Some cells are ready to go, providing only explanations.\n",
    "- In some cells, you are expected to type in the python code to carryout the specified task.\n",
    "- You are given expected output to verify your output.\n",
    "-Do not change any of the variable names created.\n",
    "- <b> Submit your Jupyter notebook on Moodle. An assignment activity as been created - 'Lab Session 1' </b>\n",
    "- <b> Due date: Wednesday, 3 August 2022, 11:00 PM </b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecffe225-8b4b-4741-b345-0adb51b61cdd",
   "metadata": {},
   "source": [
    "## Lesson 1: Basic RE in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2db2132-232a-405b-a147-6c5c72cd2b77",
   "metadata": {},
   "source": [
    "To use the re module in python, you need to import it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "287c478b-eef0-410e-8f11-66fe179551e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b957f2b-6fa4-446f-88dd-ff3690fa9646",
   "metadata": {},
   "source": [
    "Let's find all ocurrences of woodchuck in a body of text. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "527f5b2c-9dfe-4906-b4cb-d5176f2874bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function findall in module re:\n",
      "\n",
      "findall(pattern, string, flags=0)\n",
      "    Return a list of all non-overlapping matches in the string.\n",
      "    \n",
      "    If one or more capturing groups are present in the pattern, return\n",
      "    a list of groups; this will be a list of tuples if the pattern\n",
      "    has more than one group.\n",
      "    \n",
      "    Empty matches are included in the result.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#The findall function helps to return matched strings. You can use help to learn about new functions\n",
    "\n",
    "help(re.findall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e504eded-92b3-43d3-ac73-c6a8e5bfc9e7",
   "metadata": {},
   "source": [
    "How many occurences of woodchuck can you count? \n",
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc955e30-bd2c-425e-a0a3-83477771f93c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['woodchuck', 'woodchuck']\n"
     ]
    }
   ],
   "source": [
    "text = \"Woodchuck is an animal, woodchuck is a mammal, have you seen a woodchuck before?\"\n",
    "\n",
    "x = re.findall(\"woodchuck\", text)\n",
    "\n",
    "print(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddf2462d-2aac-47fd-844c-46dcd72bb5f5",
   "metadata": {},
   "source": [
    "But we only found 2? What happened? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2bd12-c6dd-4a29-9450-4d9f6ef0ffc1",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "It only returned the occurences of woodchuck starting with a lowercase letter 'w'. \n",
    "    \n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0ff3107-a182-4271-87ff-faa583de12fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['W', ' ', ' ', ' ', ' ', 'w', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', 'w', ' ']\n"
     ]
    }
   ],
   "source": [
    "#The [ ] (squarebrackets) can be used to specify a range of characters you want.\n",
    "\n",
    "x = re.findall(\"[w W]\", text)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dff1467f-d7ce-465d-8eb4-82643226cda4",
   "metadata": {},
   "source": [
    "Let's adapt that to solve our problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdccf403-a04d-4481-a2c6-f7d3dee01bf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Woodchuck', 'woodchuck', 'woodchuck']\n"
     ]
    }
   ],
   "source": [
    "# Write code to find all occurrence of woodchuck in a text \n",
    "# Your code should return a list of three items\n",
    "\n",
    "all_woodchucks = re.findall(\"[w W]oodchuck\",text)\n",
    "print(all_woodchucks)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05e9e868-2b2f-4132-89ca-019747508ab3",
   "metadata": {},
   "source": [
    "Expected Output:\n",
    "['Woodchuck', 'woodchuck', 'woodchuck']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74101faf-3cff-43bc-b910-3a497a9b886f",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    " re.findall(\"[wW]oodchuck\", text)\n",
    "\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ca0efe-dd41-47af-b2ee-41c7c39a489e",
   "metadata": {},
   "source": [
    "Find all digits?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf3f551c-44ca-40ce-a124-39249be83f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8', '3', '4', '5', '7', '8', '4', '5', '6', '7', '8', '5', '4', '5', '8', '5', '8', '5', '4']\n"
     ]
    }
   ],
   "source": [
    "text = \"jkdfgjdf8345t784567jdjdf85ti4e5df85jkdf854jkdf\"\n",
    "x = re.findall(\"[0123456789]\", text)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "694405a7-e367-4d99-9045-a47859a982b3",
   "metadata": {},
   "source": [
    "Find all uppercase letters? Do we need to write out all the 26 letters?\n",
    "\n",
    "Try using a set.\n",
    "\n",
    "A set is a set of characters inside a pair of square brackets [ ] with a special meaning:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3939f738-0565-4195-b8ba-f5966cea46d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['C', 'D', 'G', 'H', 'A', 'B', 'K', 'E', 'W', 'R', 'T', 'Y', 'K', 'Y', 'H', 'L', 'H', 'J', 'J']\n"
     ]
    }
   ],
   "source": [
    "text = \"jkdfgjdf8CDGH345t78ABKEWRTYKYHL4567jdjdf85tiHJJ4e5df85jkdf854jkdf\"\n",
    "\n",
    "# type your code here\n",
    "uppercase_letters = re.findall(\"[A-Z]\",text)\n",
    "\n",
    "print(uppercase_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31907cbb",
   "metadata": {},
   "source": [
    "Expected Output: ['C', 'D', 'G', 'H', 'A', 'B', 'K', 'E', 'W', 'R', 'T', 'Y', 'K', 'Y', 'H', 'L', 'H', 'J', 'J']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61e0efeb-a948-4a7e-a8d5-ed3263625f4b",
   "metadata": {},
   "source": [
    "<details>\n",
    "<summary>\n",
    "    <font size=\"3\" color=\"darkgreen\"><b>Hints</b></font>\n",
    "</summary>\n",
    "<p>\n",
    "x = re.findall(\"[A-Z]\", text)\n",
    "print(x)\n",
    "\n",
    "</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a88e8396-a159-465f-af44-14a247f3a59e",
   "metadata": {},
   "source": [
    "Modify the code to find both uppercase and lowercase letters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dec100a2-f795-46ce-8f24-04d66cb51835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['j', 'k', 'd', 'f', 'g', 'j', 'd', 'f', 'C', 'D', 'G', 'H', 't', 'A', 'B', 'K', 'E', 'W', 'R', 'T', 'Y', 'K', 'Y', 'H', 'L', 'j', 'd', 'j', 'd', 'f', 't', 'i', 'H', 'J', 'J', 'e', 'd', 'f', 'j', 'k', 'd', 'f', 'j', 'k', 'd', 'f']\n"
     ]
    }
   ],
   "source": [
    "text = \"jkdfgjdf8CDGH345t78ABKEWRTYKYHL4567jdjdf85tiHJJ4e5df85jkdf854jkdf\"\n",
    "\n",
    "# type your code here\n",
    "lower_uppercase_letters = re.findall(\"[a-zA-Z]\",text)\n",
    "\n",
    "print(lower_uppercase_letters)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead3feaa-e141-495a-960f-2352a43ee600",
   "metadata": {},
   "source": [
    "Negation\n",
    "\n",
    "Find all characters that are not CAPITAL A - Z\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "231fa164-7769-4df3-9844-674f885610bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['j', 'k', 'd', 'f', 'g', 'j', 'd', 'f', '8', '3', '4', '5', 't', '7', '8', '^', '4', '5', '6', '7', 'j', 'd', 'j', 'd', 'f', '8', '5', 't', 'i', '4', 'e', '5', 'd', 'f', '8', '5', 'j', 'k', 'd', 'f', '8', '5', '4', 'j', 'k', 'd', 'f']\n"
     ]
    }
   ],
   "source": [
    "text = \"jkdfgjdf8CDGH345t78ABKEWRTYKY^HL4567jdjdf85tiHJJ4e5df85jkdf854jkdf\"\n",
    "not_upper = re.findall(\"[^A-Z]\",text)\n",
    "\n",
    "print(not_upper) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcbec50-1a48-4d04-8738-b062d4eb7f89",
   "metadata": {},
   "source": [
    "Expected Output:\n",
    "    ['j', 'k', 'd', 'f', 'g', 'j', 'd', 'f', '8', '3', '4', '5', 't', '7', '8', '^', '4', '5', '6', '7', 'j', 'd', 'j', 'd', 'f', '8', '5', 't', 'i', '4', 'e', '5', 'd', 'f', '8', '5', 'j', 'k', 'd', 'f', '8', '5', '4', 'j', 'k', 'd', 'f']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ec9749-723c-4a49-8141-54fdfd22a4b6",
   "metadata": {},
   "source": [
    "Find all characters that are not CAPITAL A - Z, and not the caret symbol (i.e., ensure that the caret symbol is not returned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5efd287-6910-47d0-bc42-2033029608dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['j', 'k', 'd', 'f', 'g', 'j', 'd', 'f', '8', '3', '4', '5', 't', '7', '8', '4', '5', '6', '7', 'j', 'd', 'j', 'd', 'f', '8', '5', 't', 'i', '4', 'e', '5', 'd', 'f', '8', '5', 'j', 'k', 'd', 'f', '8', '5', '4', 'j', 'k', 'd', 'f']\n"
     ]
    }
   ],
   "source": [
    "text = \"jkdfgjdf8CDGH345t78ABKEWRTYKY^HL4567jdjdf85tiHJJ4e5df85jkdf854jkdf\"\n",
    "\n",
    "not_upper_or_caret = re.findall(\"[^A-Z^]\",text)\n",
    "\n",
    "print(not_upper_or_caret)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141cdec0-7303-4aee-8726-6c80b9d14744",
   "metadata": {},
   "source": [
    "Expected Output: ['j', 'k', 'd', 'f', 'g', 'j', 'd', 'f', '8', '3', '4', '5', 't', '7', '8', '4', '5', '6', '7', 'j', 'd', 'j', 'd', 'f', '8', '5', 't', 'i', '4', 'e', '5', 'd', 'f', '8', '5', 'j', 'k', 'd', 'f', '8', '5', '4', 'j', 'k', 'd', 'f']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43c6de94-93e2-43f3-9c63-4546e56cda93",
   "metadata": {},
   "source": [
    "Find all occurrences of woodchuck or groundhog, regardless of the case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3535e61-8bd6-4603-a57e-765ad26a15b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Woodchuck', 'woodchuck', 'woodchuck', 'groundhog', 'Groundhog']\n"
     ]
    }
   ],
   "source": [
    "text = \"Woodchuck is an animal, woodchuck is a mammal, have you seen a woodchuck. It is also called groundhog, yes Groundhog\"\n",
    "\n",
    "all_woodchuck_groundhog = re.findall(\"[Ww]oodchuck|[Gg]roundhog\", text)\n",
    "\n",
    "\n",
    "print(all_woodchuck_groundhog)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5539d39e-b1f7-4733-93c5-bb167f597b56",
   "metadata": {},
   "source": [
    "Expected Output: ['Woodchuck', 'woodchuck', 'woodchuck', 'groundhog', 'Groundhog']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1fa1f58-23d4-4287-9cda-35615c2f96ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YES it does\n"
     ]
    }
   ],
   "source": [
    "#Use the search function to check if a string starts and ends with a word\n",
    "txt = \"Woodchuck is an animal, woodchuck is a mammal, have you seen a woodchuck. It is also called groundhog, yes Groundhog\"\n",
    "x = re.search(\"^Woodchuck.*Groundhog$\", txt)\n",
    "\n",
    "if x:\n",
    "    print(\"YES it does\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6fba7bbb-2edf-49ea-b753-4c2d87b9915f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " ' is an animal, ',\n",
       " ' is a mammal, have you seen a ',\n",
       " '. it is also called ',\n",
       " ', yes ',\n",
       " '']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use the split() function. Split the text at anypoint there is the word 'woodchuck' or 'groundhog', regardless of the case\n",
    "txt = \"Woodchuck is an animal, woodchuck is a mammal, have you seen a woodchuck. It is also called groundhog, yes Groundhog\"\n",
    "x = re.split(\"woodchuck|groundhog\", txt.lower())\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "334a856e-95b6-4579-b2e6-6695c3b5291a",
   "metadata": {},
   "source": [
    "Change all occurrence of woodchuck or groundhog to rhino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e8533d75-99ea-4acb-b888-4ef521c3a62c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rhino is an animal, rhino is a mammal, have you seen a rhino. It is also called rhino, yes rhino'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the sub function to substitute\n",
    "# to delete a text, you can substitute with an empty string\n",
    "txt = \"Woodchuck is an animal, woodchuck is a mammal, have you seen a woodchuck. It is also called groundhog, yes Groundhog\"\n",
    "new_text = re.sub(r'[Ww]oodchuck|[Gg]roundhog',\"rhino\",txt)\n",
    "new_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a0ddd5-cf9d-48f3-9acc-bdb1b6e6c830",
   "metadata": {},
   "source": [
    "## Lesson 2: Preprocessing Tweets\n",
    "\n",
    "Let's assume we have a set of tweets we want to perform sentiment analysis on. Usually, the first step of any machine learning task is to clean/preprocess the data. Data preprocessing in NLP includes tasks like tokenizing, lowercasing, removing stop words and punctuation, stemming. We'll cover most of these in our next lecture.\n",
    "\n",
    "For this exercise, our aim is simple - to remove substrings that are peculiar to the twitter platform as this might not give any useful information during sentiment analysis.\n",
    "\n",
    "Task: Given a  set of tweets, remove the following using regular expressions:\n",
    "1. hashtags (#): Remove all occurrences of the hashtag symbol\n",
    "2. retweet marks (RT): Remove the first occurrence of RT followed by one or more spaces, when present in a tweet \n",
    "3. hyperlinks: Remove everyoccurrence of 'http://...' where ... represents any character that is not a space, newline or carriage return character.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6b5059-92bc-489c-86d4-0afe9a112dd0",
   "metadata": {},
   "source": [
    "Please note that we are using a public dataset from the NLTK (Natural Language Tool Kit), as such I do not have control over the content of the text therein."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7e3f6f-bbcf-4664-a691-e7bd15059ba7",
   "metadata": {},
   "source": [
    "\n",
    "Steps:\n",
    "1. Import the sample Twitter dataset from NLTK "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c35577da-0fbc-4869-8bd9-a84fb36e2aa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package twitter_samples to\n",
      "[nltk_data]     C:\\Users\\yasee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package twitter_samples is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk                                # Python library for NLP\n",
    "from nltk.corpus import twitter_samples    # sample Twitter dataset from NLTK\n",
    "# downloads sample twitter dataset.\n",
    "nltk.download('twitter_samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f03ab064-424f-42ef-8e94-14162dccce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select the set of positive and negative tweets\n",
    "all_positive_tweets = twitter_samples.strings('positive_tweets.json')\n",
    "all_negative_tweets = twitter_samples.strings('negative_tweets.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "567d999c-7265-40ee-ad8c-ce99476ac403",
   "metadata": {},
   "source": [
    "This dataset contains 5000 positive and 5000 negative tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c448abb5-85fd-49b9-bf82-dcbda1bab13f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_positive_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cda462dd-1136-44b0-bcb7-cb11fb38b985",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(all_negative_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71522280-f615-4a83-96d4-1e857559fb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hopeless for tmr :(',\n",
       " \"Everything in the kids section of IKEA is so cute. Shame I'm nearly 19 in 2 months :(\",\n",
       " '@Hegelbon That heart sliding into the waste basket. :(',\n",
       " '“@ketchBurning: I hate Japanese call him \"bani\" :( :(”\\n\\nMe too',\n",
       " 'Dang starting next week I have \"work\" :(',\n",
       " \"oh god, my babies' faces :( https://t.co/9fcwGvaki0\",\n",
       " '@RileyMcDonough make me smile :((',\n",
       " '@f0ggstar @stuartthull work neighbour on motors. Asked why and he said hates the updates on search :( http://t.co/XvmTUikWln',\n",
       " 'why?:(\"@tahuodyy: sialan:( https://t.co/Hv1i0xcrL2\"',\n",
       " 'Athabasca glacier was there in #1948 :-( #athabasca #glacier #jasper #jaspernationalpark #alberta #explorealberta #… http://t.co/dZZdqmf7Cz',\n",
       " \"I have a really good m&amp;g idea but I'm never going to meet them :(((\",\n",
       " '@Rampageinthebox mare ivan :(',\n",
       " '@SophiaMascardo happy trip, keep safe. see you soon :* :(',\n",
       " \"I'm so tired hahahah :(\",\n",
       " '@GrumpyCockney With knee replacements they get you up &amp; about the same day. :-(   Ouch.']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_negative_tweets[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a1a0df26-07e7-49b9-914b-3068be0ad2fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = all_negative_tweets[9]\n",
    "tweet = '''RT Athabasca glacier was RT there in #1948 :-( #athabasca #glacier #jasper #jaspernationalpark #alberta #explorealberta #… http://t.co/dZZdqmf7Cz'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ea103ab-e756-4e67-9e5b-75aab3ee13ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning: RT Athabasca glacier was RT there in #1948 :-( #athabasca #glacier #jasper #jaspernationalpark #alberta #explorealberta #… http://t.co/dZZdqmf7Cz \n",
      "After cleaning:  Athabasca glacier was  there in 1948 :-( athabasca glacier jasper jaspernationalpark alberta explorealberta … \n"
     ]
    }
   ],
   "source": [
    "def clean_tweets(tweet):\n",
    "    # remove  \"RT\"\n",
    "    cleaned_tweet = re.sub(\"RT\",\"\",tweet)\n",
    "    \n",
    "    # remove hyperlinks\n",
    "    cleaned_tweet = re.sub(\"http.*\",\"\",cleaned_tweet)\n",
    "    \n",
    "    # remove hashtags\n",
    "    # only removing the hash # sign from the word\n",
    "    cleaned_tweet = re.sub(\"[#]\",\"\",cleaned_tweet)\n",
    "    \n",
    "    \n",
    "    return cleaned_tweet\n",
    "\n",
    "print(\"Before cleaning:\", tweet, \"\\nAfter cleaning:\", clean_tweets(tweet))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1302aa12-cc71-43af-8d3b-4b7adc490eba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning: @BhaktisBanter @PallaviRuhail This one is irresistible :)\n",
      "#FlipkartFashionFriday http://t.co/EbZ0L2VENM \n",
      "After  cleaning: @BhaktisBanter @PallaviRuhail This one is irresistible :)\n",
      "FlipkartFashionFriday  \n",
      "\n",
      "Before cleaning: @AvinPera  follow @jnlazts &amp; http://t.co/RCvcYYO0Iq follow u back :) \n",
      "After  cleaning: @AvinPera  follow @jnlazts &amp;  \n",
      "\n",
      "Before cleaning: @mrkennyt90 Yesss I am thank you :D \n",
      "After  cleaning: @mrkennyt90 Yesss I am thank you :D \n",
      "\n",
      "Before cleaning: @calllmejay_ sounds good to me :) I'll see you Saturday ✨ \n",
      "After  cleaning: @calllmejay_ sounds good to me :) I'll see you Saturday ✨ \n",
      "\n",
      "Before cleaning: As if bank credit departments weren't bad enough, ANZ has gone to the extreme of offshoring theirs!!! Absolutely classic :-)\n",
      "#gottolovebanks \n",
      "After  cleaning: As if bank credit departments weren't bad enough, ANZ has gone to the extreme of offshoring theirs!!! Absolutely classic :-)\n",
      "gottolovebanks \n",
      "\n",
      "Before cleaning: @LouosaurusRex happiest of Fridays to you! have a great weekend :D \n",
      "After  cleaning: @LouosaurusRex happiest of Fridays to you! have a great weekend :D \n",
      "\n",
      "Before cleaning: @jitenkumargupta Thanks for the sharing the article :) @thebetterindia \n",
      "After  cleaning: @jitenkumargupta Thanks for the sharing the article :) @thebetterindia \n",
      "\n",
      "Before cleaning: hahaha.. yeeaayy. .. today i'm so HAPPY! !!! .. alhamdulillah God :) \n",
      "After  cleaning: hahaha.. yeeaayy. .. today i'm so HAPPY! !!! .. alhamdulillah God :) \n",
      "\n",
      "Before cleaning: @oppentrapp Cool :D \n",
      "After  cleaning: @oppentrapp Cool :D \n",
      "\n",
      "Before cleaning: New story illustration for your visual pleasure. Thanks for looking :) https://t.co/zIITPKlIPz \n",
      "After  cleaning: New story illustration for your visual pleasure. Thanks for looking :)  \n",
      "\n",
      "Before cleaning: Made Cajun chicken with spiced Couscous for dinner! So yum :)\n",
      "#cajunchicken #couscous #food #dinner… https://t.co/kkTgTf0qVG \n",
      "After  cleaning: Made Cajun chicken with spiced Couscous for dinner! So yum :)\n",
      "cajunchicken couscous food dinner…  \n",
      "\n",
      "Before cleaning: Thanks a million for keeping an eye on our tweets, always appreciated :) @lagganmountains @Yantilly http://t.co/liCJPzz21k \n",
      "After  cleaning: Thanks a million for keeping an eye on our tweets, always appreciated :) @lagganmountains @Yantilly  \n",
      "\n",
      "Before cleaning: @biltongstmarcus Hi, do you stock Marmite Cheese Spread at all? Thanks :) \n",
      "After  cleaning: @biltongstmarcus Hi, do you stock Marmite Cheese Spread at all? Thanks :) \n",
      "\n",
      "Before cleaning: @ReetAwwsum Great! Did you reserve for Windows 10? :) ^MM \n",
      "After  cleaning: @ReetAwwsum Great! Did you reserve for Windows 10? :) ^MM \n",
      "\n",
      "Before cleaning: @ICTDSeSafety Its on my to do list, just about to board so see you in a couple of weeks :-) \n",
      "After  cleaning: @ICTDSeSafety Its on my to do list, just about to board so see you in a couple of weeks :-) \n",
      "\n",
      "Before cleaning: @sommie0506 My app is looking for influencers :) If you're interested, here's your invite http://t.co/ipJ2yOiGet \n",
      "After  cleaning: @sommie0506 My app is looking for influencers :) If you're interested, here's your invite  \n",
      "\n",
      "Before cleaning: @Sazzi91 we are following you now :) x \n",
      "After  cleaning: @Sazzi91 we are following you now :) x \n",
      "\n",
      "Before cleaning: Hey Fam! Vote for @5SOS if you haven't already :) WE GOTTA WIN THIS FOR OUR BOYS! #TeenChoice -S http://t.co/zBZvXC0v5y \n",
      "After  cleaning: Hey Fam! Vote for @5SOS if you haven't already :) WE GOTTA WIN THIS FOR OUR BOYS! TeenChoice -S  \n",
      "\n",
      "Before cleaning: @The_Sleigher among my all time fav tweets :D \n",
      "After  cleaning: @The_Sleigher among my all time fav tweets :D \n",
      "\n",
      "Before cleaning: @SaddestTiger @davedittell   Good night, Tiger!  Sweet furry dreams!   : ) xxoo \n",
      "After  cleaning: @SaddestTiger @davedittell   Good night, Tiger!  Sweet furry dreams!   : ) xxoo \n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Run this to verify your output\n",
    "for i in range(5, 5000, 250):\n",
    "    tweet = clean_tweets(all_positive_tweets[i])\n",
    "    print(\"Before cleaning:\", all_positive_tweets[i], \"\\nAfter  cleaning:\", clean_tweets(tweet), \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "978a0162-6efa-4ce8-8cb3-334ca366f0e9",
   "metadata": {},
   "source": [
    "Expected Output:\n",
    "    \n",
    "Before cleaning: @BhaktisBanter @PallaviRuhail This one is irresistible :)\n",
    "#FlipkartFashionFriday http://t.co/EbZ0L2VENM \n",
    "\n",
    "After  cleaning: @BhaktisBanter @PallaviRuhail This one is irresistible :)\n",
    "FlipkartFashionFriday  \n",
    "\n",
    "Before cleaning: @AvinPera  follow @jnlazts &amp; http://t.co/RCvcYYO0Iq follow u back :)\n",
    "\n",
    "After  cleaning: @AvinPera  follow @jnlazts &amp;  follow u back :) \n",
    "\n",
    "Before cleaning: @mrkennyt90 Yesss I am thank you :D \n",
    "\n",
    "After  cleaning: @mrkennyt90 Yesss I am thank you :D \n",
    "\n",
    "Before cleaning: @calllmejay_ sounds good to me :) I'll see you Saturday ✨ \n",
    "\n",
    "After  cleaning: @calllmejay_ sounds good to me :) I'll see you Saturday ✨ \n",
    "\n",
    "Before cleaning: As if bank credit departments weren't bad enough, ANZ has gone to the extreme of offshoring theirs!!! Absolutely classic :-)\n",
    "#gottolovebanks \n",
    "\n",
    "After  cleaning: As if bank credit departments weren't bad enough, ANZ has gone to the extreme of offshoring theirs!!! Absolutely classic :-)\n",
    "gottolovebanks \n",
    "\n",
    "Before cleaning: @LouosaurusRex happiest of Fridays to you! have a great weekend :D\n",
    "\n",
    "After  cleaning: @LouosaurusRex happiest of Fridays to you! have a great weekend :D \n",
    "\n",
    "Before cleaning: @jitenkumargupta Thanks for the sharing the article :) @thebetterindia \n",
    "\n",
    "After  cleaning: @jitenkumargupta Thanks for the sharing the article :) @thebetterindia \n",
    "\n",
    "Before cleaning: hahaha.. yeeaayy. .. today i'm so HAPPY! !!! .. alhamdulillah God :) \n",
    "\n",
    "After  cleaning: hahaha.. yeeaayy. .. today i'm so HAPPY! !!! .. alhamdulillah God :) \n",
    "\n",
    "Before cleaning: @oppentrapp Cool :D \n",
    "\n",
    "After  cleaning: @oppentrapp Cool :D \n",
    "\n",
    "Before cleaning: New story illustration for your visual pleasure. Thanks for looking :) https://t.co/zIITPKlIPz \n",
    "\n",
    "After  cleaning: New story illustration for your visual pleasure. Thanks for looking :)  \n",
    "\n",
    "Before cleaning: Made Cajun chicken with spiced Couscous for dinner! So yum :)\n",
    "#cajunchicken #couscous #food #dinner… https://t.co/kkTgTf0qVG \n",
    "\n",
    "After  cleaning: Made Cajun chicken with spiced Couscous for dinner! So yum :)\n",
    "cajunchicken couscous food dinner…  \n",
    "\n",
    "Before cleaning: Thanks a million for keeping an eye on our tweets, always appreciated :) @lagganmountains @Yantilly http://t.co/liCJPzz21k \n",
    "\n",
    "After  cleaning: Thanks a million for keeping an eye on our tweets, always appreciated :) @lagganmountains @Yantilly  \n",
    "\n",
    "Before cleaning: @biltongstmarcus Hi, do you stock Marmite Cheese Spread at all? Thanks :)\n",
    "\n",
    "After  cleaning: @biltongstmarcus Hi, do you stock Marmite Cheese Spread at all? Thanks :) \n",
    "\n",
    "Before cleaning: @ReetAwwsum Great! Did you reserve for Windows 10? :) ^MM \n",
    "\n",
    "After  cleaning: @ReetAwwsum Great! Did you reserve for Windows 10? :) ^MM \n",
    "\n",
    "Before cleaning: @ICTDSeSafety Its on my to do list, just about to board so see you in a couple of weeks :-) \n",
    "\n",
    "After  cleaning: @ICTDSeSafety Its on my to do list, just about to board so see you in a couple of weeks :-) \n",
    "\n",
    "Before cleaning: @sommie0506 My app is looking for influencers :) If you're interested, here's your invite http://t.co/ipJ2yOiGet \n",
    "\n",
    "After  cleaning: @sommie0506 My app is looking for influencers :) If you're interested, here's your invite  \n",
    "\n",
    "Before cleaning: @Sazzi91 we are following you now :) x \n",
    "\n",
    "After  cleaning: @Sazzi91 we are following you now :) x \n",
    "\n",
    "Before cleaning: Hey Fam! Vote for @5SOS if you haven't already :) WE GOTTA WIN THIS FOR OUR BOYS! #TeenChoice -S http://t.co/zBZvXC0v5y \n",
    "\n",
    "After  cleaning: Hey Fam! Vote for @5SOS if you haven't already :) WE GOTTA WIN THIS FOR OUR BOYS! TeenChoice -S  \n",
    "\n",
    "Before cleaning: @The_Sleigher among my all time fav tweets :D \n",
    "\n",
    "After  cleaning: @The_Sleigher among my all time fav tweets :D \n",
    "\n",
    "Before cleaning: @SaddestTiger @davedittell   Good night, Tiger!  Sweet furry dreams!   : ) xxoo \n",
    "\n",
    "After  cleaning: @SaddestTiger @davedittell   Good night, Tiger!  Sweet furry dreams!   : ) xxoo \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
