{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Yaseen Haffejee: 1827555 \n",
    "# Spam Classification Using Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: anyio==3.6.2 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 1)) (3.6.2)\n",
      "Requirement already satisfied: argon2-cffi==21.3.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 2)) (21.3.0)\n",
      "Requirement already satisfied: argon2-cffi-bindings==21.2.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 3)) (21.2.0)\n",
      "Requirement already satisfied: asttokens==2.1.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 4)) (2.1.0)\n",
      "Requirement already satisfied: attrs==22.1.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 5)) (22.1.0)\n",
      "Requirement already satisfied: backcall==0.2.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 6)) (0.2.0)\n",
      "Requirement already satisfied: backports.functools-lru-cache==1.6.4 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 7)) (1.6.4)\n",
      "Requirement already satisfied: beautifulsoup4==4.11.1 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 8)) (4.11.1)\n",
      "Requirement already satisfied: bleach==5.0.1 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 9)) (5.0.1)\n",
      "Requirement already satisfied: cachier==1.5.4 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 10)) (1.5.4)\n",
      "Requirement already satisfied: certifi==2022.9.24 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 11)) (2022.9.24)\n",
      "Requirement already satisfied: cffi==1.15.1 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 12)) (1.15.1)\n",
      "Requirement already satisfied: click==8.1.3 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 13)) (8.1.3)\n",
      "Requirement already satisfied: colorama==0.4.6 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 14)) (0.4.6)\n",
      "Requirement already satisfied: debugpy==1.6.3 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 15)) (1.6.3)\n",
      "Requirement already satisfied: decorator==5.1.1 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 16)) (5.1.1)\n",
      "Requirement already satisfied: defusedxml==0.7.1 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 17)) (0.7.1)\n",
      "Requirement already satisfied: entrypoints==0.4 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 18)) (0.4)\n",
      "Requirement already satisfied: executing==1.2.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 19)) (1.2.0)\n",
      "Requirement already satisfied: fastjsonschema==2.16.2 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 20)) (2.16.2)\n",
      "Requirement already satisfied: flit_core==3.7.1 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 21)) (3.7.1)\n",
      "Requirement already satisfied: idna==3.4 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 22)) (3.4)\n",
      "Requirement already satisfied: importlib-metadata==5.0.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 23)) (5.0.0)\n",
      "Requirement already satisfied: importlib-resources==5.10.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 24)) (5.10.0)\n",
      "Requirement already satisfied: ipykernel==6.17.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 25)) (6.17.0)\n",
      "Requirement already satisfied: ipython==8.6.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 26)) (8.6.0)\n",
      "Requirement already satisfied: ipython-genutils==0.2.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 27)) (0.2.0)\n",
      "Requirement already satisfied: ipywidgets==8.0.2 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 28)) (8.0.2)\n",
      "Requirement already satisfied: jedi==0.18.1 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 29)) (0.18.1)\n",
      "Requirement already satisfied: Jinja2==3.1.2 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 30)) (3.1.2)\n",
      "Requirement already satisfied: joblib==1.2.0 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 31)) (1.2.0)\n",
      "Requirement already satisfied: jsonschema==4.17.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 32)) (4.17.0)\n",
      "Requirement already satisfied: jupyter==1.0.0 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 33)) (1.0.0)\n",
      "Requirement already satisfied: jupyter_client==7.4.4 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 34)) (7.4.4)\n",
      "Requirement already satisfied: jupyter-console==6.4.4 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 35)) (6.4.4)\n",
      "Requirement already satisfied: jupyter_core==4.11.2 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 36)) (4.11.2)\n",
      "Requirement already satisfied: jupyter-server==1.21.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 37)) (1.21.0)\n",
      "Requirement already satisfied: jupyterlab-pygments==0.2.2 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 38)) (0.2.2)\n",
      "Requirement already satisfied: jupyterlab-widgets==3.0.3 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 39)) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe==2.1.1 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 40)) (2.1.1)\n",
      "Requirement already satisfied: matplotlib-inline==0.1.6 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 41)) (0.1.6)\n",
      "Requirement already satisfied: mistune==2.0.4 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 42)) (2.0.4)\n",
      "Requirement already satisfied: nbclassic==0.4.8 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 43)) (0.4.8)\n",
      "Requirement already satisfied: nbclient==0.7.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 44)) (0.7.0)\n",
      "Requirement already satisfied: nbconvert==7.2.3 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 45)) (7.2.3)\n",
      "Requirement already satisfied: nbformat==5.7.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 46)) (5.7.0)\n",
      "Requirement already satisfied: nest-asyncio==1.5.6 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 47)) (1.5.6)\n",
      "Requirement already satisfied: nltk==3.7 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 48)) (3.7)\n",
      "Requirement already satisfied: notebook==6.5.2 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 49)) (6.5.2)\n",
      "Requirement already satisfied: notebook_shim==0.2.2 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 50)) (0.2.2)\n",
      "Requirement already satisfied: numpy==1.23.4 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 51)) (1.23.4)\n",
      "Requirement already satisfied: packaging==21.3 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 52)) (21.3)\n",
      "Requirement already satisfied: pandas==1.5.1 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 53)) (1.5.1)\n",
      "Requirement already satisfied: pandocfilters==1.5.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 54)) (1.5.0)\n",
      "Requirement already satisfied: parso==0.8.3 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 55)) (0.8.3)\n",
      "Requirement already satisfied: pathtools==0.1.2 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 56)) (0.1.2)\n",
      "Requirement already satisfied: pickleshare==0.7.5 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 57)) (0.7.5)\n",
      "Requirement already satisfied: pip==22.3 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 58)) (22.3)\n",
      "Requirement already satisfied: pkgutil_resolve_name==1.3.10 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 59)) (1.3.10)\n",
      "Requirement already satisfied: portalocker==2.6.0 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 60)) (2.6.0)\n",
      "Requirement already satisfied: prometheus-client==0.15.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 61)) (0.15.0)\n",
      "Requirement already satisfied: prompt-toolkit==3.0.32 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 62)) (3.0.32)\n",
      "Requirement already satisfied: psutil==5.9.3 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 63)) (5.9.3)\n",
      "Requirement already satisfied: pure-eval==0.2.2 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 64)) (0.2.2)\n",
      "Requirement already satisfied: py2opt==1.3.6 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 65)) (1.3.6)\n",
      "Requirement already satisfied: pycparser==2.21 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 66)) (2.21)\n",
      "Requirement already satisfied: Pygments==2.13.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 67)) (2.13.0)\n",
      "Requirement already satisfied: pyparsing==3.0.9 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 68)) (3.0.9)\n",
      "Requirement already satisfied: pyrsistent==0.19.2 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 69)) (0.19.2)\n",
      "Requirement already satisfied: python-dateutil==2.8.2 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 70)) (2.8.2)\n",
      "Requirement already satisfied: pytz==2022.6 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 71)) (2022.6)\n",
      "Requirement already satisfied: pywin32==304 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 72)) (304)\n",
      "Requirement already satisfied: pywinpty==2.0.9 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 73)) (2.0.9)\n",
      "Requirement already satisfied: pyzmq==24.0.1 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 74)) (24.0.1)\n",
      "Requirement already satisfied: qtconsole==5.4.0 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 75)) (5.4.0)\n",
      "Requirement already satisfied: QtPy==2.2.1 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 76)) (2.2.1)\n",
      "Requirement already satisfied: random2==1.0.1 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 77)) (1.0.1)\n",
      "Requirement already satisfied: regex==2022.10.31 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 78)) (2022.10.31)\n",
      "Requirement already satisfied: scikit-learn==1.1.3 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 79)) (1.1.3)\n",
      "Requirement already satisfied: scipy==1.9.3 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 80)) (1.9.3)\n",
      "Requirement already satisfied: Send2Trash==1.8.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 81)) (1.8.0)\n",
      "Requirement already satisfied: setuptools==65.5.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 82)) (65.5.0)\n",
      "Requirement already satisfied: six==1.16.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 83)) (1.16.0)\n",
      "Requirement already satisfied: sniffio==1.3.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 84)) (1.3.0)\n",
      "Requirement already satisfied: soupsieve==2.3.2.post1 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 85)) (2.3.2.post1)\n",
      "Requirement already satisfied: stack-data==0.6.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 86)) (0.6.0)\n",
      "Requirement already satisfied: terminado==0.17.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 87)) (0.17.0)\n",
      "Requirement already satisfied: threadpoolctl==3.1.0 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 88)) (3.1.0)\n",
      "Requirement already satisfied: tinycss2==1.2.1 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 89)) (1.2.1)\n",
      "Requirement already satisfied: tornado==6.2 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 90)) (6.2)\n",
      "Requirement already satisfied: tqdm==4.64.1 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 91)) (4.64.1)\n",
      "Requirement already satisfied: traitlets==5.5.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 92)) (5.5.0)\n",
      "Requirement already satisfied: typing_extensions==4.4.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 93)) (4.4.0)\n",
      "Requirement already satisfied: wcwidth==0.2.5 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 94)) (0.2.5)\n",
      "Requirement already satisfied: webencodings==0.5.1 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 95)) (0.5.1)\n",
      "Requirement already satisfied: websocket-client==1.4.2 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 96)) (1.4.2)\n",
      "Requirement already satisfied: wheel==0.37.1 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 97)) (0.37.1)\n",
      "Requirement already satisfied: widgetsnbextension==4.0.3 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from -r requirements.txt (line 98)) (4.0.3)\n",
      "Requirement already satisfied: wincertstore==0.2 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 99)) (0.2)\n",
      "Requirement already satisfied: zipp==3.10.0 in c:\\programdata\\anaconda3\\envs\\temp\\lib\\site-packages (from -r requirements.txt (line 100)) (3.10.0)\n",
      "Requirement already satisfied: watchdog in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from cachier==1.5.4->-r requirements.txt (line 10)) (2.1.9)\n",
      "Requirement already satisfied: pytest in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from py2opt==1.3.6->-r requirements.txt (line 65)) (7.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc8 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from pytest->py2opt==1.3.6->-r requirements.txt (line 65)) (1.0.1)\n",
      "Requirement already satisfied: tomli>=1.0.0 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from pytest->py2opt==1.3.6->-r requirements.txt (line 65)) (2.0.1)\n",
      "Requirement already satisfied: pluggy<2.0,>=0.12 in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from pytest->py2opt==1.3.6->-r requirements.txt (line 65)) (1.0.0)\n",
      "Requirement already satisfied: iniconfig in c:\\users\\yasee\\appdata\\roaming\\python\\python39\\site-packages (from pytest->py2opt==1.3.6->-r requirements.txt (line 65)) (1.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\yasee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\yasee\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import accuracy_score, precision_score,recall_score,f1_score\n",
    "from collections import Counter\n",
    "import nltk\n",
    "nltk.download('wordnet')\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Helper Functions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(model_output,true_output):\n",
    "\n",
    "    accuracy = np.round(accuracy_score(model_output,true_output),3)\n",
    "    precision = np.round(precision_score(model_output,true_output),3)\n",
    "    recall = np.round(recall_score(model_output,true_output),3)\n",
    "    f1 = np.round(f1_score(model_output,true_output),3)\n",
    "\n",
    "    print(f\"The accuracy score is {accuracy}.\")\n",
    "    print(f\"The precision score is {precision}.\")\n",
    "    print(f\"The recall score is {recall}.\")\n",
    "    print(f\"The f1 score is {f1}.\")\n",
    "\n",
    "    return [accuracy,precision,recall,f1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "### 1. Preprocess the data, tokenize the text, and get a list of words for each sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"./project_1_data/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Subject: thank you\\r\\nami and daren , , , ,\\r\\...\n",
       "1    Subject: spot or firm tickets\\r\\nvance ,\\r\\nth...\n",
       "2    Subject: software\\r\\nmicrosoft windows xp prof...\n",
       "3    Subject: noms / actual flow for 2 / 27\\r\\nwe a...\n",
       "4    Subject: superb so . ftware\\r\\nyoull discover ...\n",
       "5    Subject: hpl nomination changes for july 25 an...\n",
       "6    Subject: dear customer your details have been ...\n",
       "7    Subject: woww . . 8 o - % off abazis\\r\\nthe lo...\n",
       "8    Subject: 3 / 1 / 2000 noms\\r\\neffective 3 / 1 ...\n",
       "9    Subject: hl & p\\r\\ndaren - also , the deal mig...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)['text']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that every new line is denoted by a '\\r\\n' combination. We can thus replace these with a space.\n",
    "- For standardisation, we will convert all emails into lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    if(type(text) is int):\n",
    "        return None\n",
    "\n",
    "  # Convert to lower case \n",
    "    text = text.lower()\n",
    "\n",
    "  # Remove all unncessary characters\n",
    "    text = re.sub('[^a-zA-Z0-9\\n]', ' ', text)\n",
    "  # Splitting into a list of words\n",
    "    list_of_words = text.split()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    list_of_words = [lemmatizer.lemmatize(word) for word in list_of_words]\n",
    "    return list_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['filtered_text'] = train['text'].apply(lambda email: preprocess(email))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>filtered_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Subject: thank you\\r\\nami and daren , , , ,\\r\\...</td>\n",
       "      <td>0</td>\n",
       "      <td>[subject, thank, you, ami, and, daren, just, w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Subject: spot or firm tickets\\r\\nvance ,\\r\\nth...</td>\n",
       "      <td>0</td>\n",
       "      <td>[subject, spot, or, firm, ticket, vance, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Subject: software\\r\\nmicrosoft windows xp prof...</td>\n",
       "      <td>1</td>\n",
       "      <td>[subject, software, microsoft, window, xp, pro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Subject: noms / actual flow for 2 / 27\\r\\nwe a...</td>\n",
       "      <td>0</td>\n",
       "      <td>[subject, noms, actual, flow, for, 2, 27, we, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Subject: superb so . ftware\\r\\nyoull discover ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[subject, superb, so, ftware, youll, discover,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Subject: hpl nomination changes for july 25 an...</td>\n",
       "      <td>0</td>\n",
       "      <td>[subject, hpl, nomination, change, for, july, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Subject: dear customer your details have been ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[subject, dear, customer, your, detail, have, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Subject: woww . . 8 o - % off abazis\\r\\nthe lo...</td>\n",
       "      <td>1</td>\n",
       "      <td>[subject, woww, 8, o, off, abazis, the, lowest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Subject: 3 / 1 / 2000 noms\\r\\neffective 3 / 1 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[subject, 3, 1, 2000, noms, effective, 3, 1, 2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Subject: hl &amp; p\\r\\ndaren - also , the deal mig...</td>\n",
       "      <td>0</td>\n",
       "      <td>[subject, hl, p, daren, also, the, deal, might...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Subject: thank you\\r\\nami and daren , , , ,\\r\\...      0   \n",
       "1  Subject: spot or firm tickets\\r\\nvance ,\\r\\nth...      0   \n",
       "2  Subject: software\\r\\nmicrosoft windows xp prof...      1   \n",
       "3  Subject: noms / actual flow for 2 / 27\\r\\nwe a...      0   \n",
       "4  Subject: superb so . ftware\\r\\nyoull discover ...      1   \n",
       "5  Subject: hpl nomination changes for july 25 an...      0   \n",
       "6  Subject: dear customer your details have been ...      1   \n",
       "7  Subject: woww . . 8 o - % off abazis\\r\\nthe lo...      1   \n",
       "8  Subject: 3 / 1 / 2000 noms\\r\\neffective 3 / 1 ...      0   \n",
       "9  Subject: hl & p\\r\\ndaren - also , the deal mig...      0   \n",
       "\n",
       "                                       filtered_text  \n",
       "0  [subject, thank, you, ami, and, daren, just, w...  \n",
       "1  [subject, spot, or, firm, ticket, vance, the, ...  \n",
       "2  [subject, software, microsoft, window, xp, pro...  \n",
       "3  [subject, noms, actual, flow, for, 2, 27, we, ...  \n",
       "4  [subject, superb, so, ftware, youll, discover,...  \n",
       "5  [subject, hpl, nomination, change, for, july, ...  \n",
       "6  [subject, dear, customer, your, detail, have, ...  \n",
       "7  [subject, woww, 8, o, off, abazis, the, lowest...  \n",
       "8  [subject, 3, 1, 2000, noms, effective, 3, 1, 2...  \n",
       "9  [subject, hl, p, daren, also, the, deal, might...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracting the vocabulary from the corpus for personal testing\n",
    "\n",
    "- Vocabulary is a dictionary sorted in descending order by frequency.\n",
    "- We can use this to test if the extracted features are correct etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = []\n",
    "\n",
    "for email in train.filtered_text:\n",
    "    vocabulary.extend(email)\n",
    "\n",
    "## Getting a count of each word in the vocabulary\n",
    "vocabulary = Counter(vocabulary)\n",
    "## Sorting the words in the vocabulary by their frequency in descending order\n",
    "vocabulary = dict(sorted(vocabulary.items(), key=lambda item: item[1],reverse=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "### 2. Train a standard Naive Bayes model. Call this Model1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - Naive Bayes cannot just take in random strings. \n",
    " - We need to extract the features, which is the frequency of words.\n",
    " - Therefore we will use Count vectorizer to get a a sparse matrix of the shape (n_samples x n_features).\n",
    " - n_features is the number of words we are using as features which changes in subtasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(analyzer=lambda x: x)\n",
    "X = cv.fit_transform(train.filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model1 = MultinomialNB()\n",
    "Model1.fit(X,train.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3\n",
    "### 3. Train 4 additional Naïve Bayes models with the following variations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### a. Use only the 10 most frequent words as features. Call this Model2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Number of features extracted: Passed !\n"
     ]
    }
   ],
   "source": [
    "## Change the count vectorizer to get only the top 10 most fequent words as features\n",
    "CV_top_10 = CountVectorizer(analyzer=lambda x: x, max_features=10 )\n",
    "X_top_10 = CV_top_10.fit_transform(train.filtered_text)\n",
    "assert(X_top_10.toarray().shape[1] == 10),print(\"Incorrect Number of features extracted\")\n",
    "assert(sorted(CV_top_10.get_feature_names_out()) == sorted(list(vocabulary.keys())[:10])),print(\"Incorrect features are being extracted\")\n",
    "print(\"Correct Number of features extracted: Passed !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model2 = MultinomialNB()\n",
    "Model2.fit(X_top_10,train.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### b. Use only the 100 most frequent words as features. Call this Model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Number of features extracted: Passed !\n"
     ]
    }
   ],
   "source": [
    "## Change the count vectorizer to get only the top 100 most fequent words as features\n",
    "CV_top_100 = CountVectorizer(analyzer=lambda x: x, max_features=100 )\n",
    "X_top_100 = CV_top_100.fit_transform(train.filtered_text)\n",
    "assert(X_top_100.toarray().shape[1] == 100),print(\"Incorrect Number of features extracted\")\n",
    "assert(sorted(CV_top_100.get_feature_names_out()) == sorted(list(vocabulary.keys())[:100])),print(\"Incorrect features are being extracted\")\n",
    "print(\"Correct Number of features extracted: Passed !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model3 = MultinomialNB()\n",
    "Model3.fit(X_top_100,train.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### c. Remove the 100 most frequent words from the features. Call this Model4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In order to remove the top 100 features, we can simply make sure the vocabulary excludes these words.\n",
    "- Consequently, all words with a frequency in the top 100 will be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Number of features extracted: Passed !\n"
     ]
    }
   ],
   "source": [
    "new_vocab_excluding_top_100 = list(vocabulary.keys())[100:]\n",
    "CV = CountVectorizer(analyzer=lambda x: x,vocabulary=new_vocab_excluding_top_100)\n",
    "X_remove_top_100 = CV.fit_transform(train.filtered_text)\n",
    "assert(X_remove_top_100.toarray().shape[1] == X.shape[1]-100),print(\"Incorrect Number of features extracted\")\n",
    "assert(sorted(CV.get_feature_names_out()) == sorted(list(vocabulary.keys())[100:])),print(\"Incorrect features are being extracted\")\n",
    "print(\"Correct Number of features extracted: Passed !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model4 = MultinomialNB()\n",
    "Model4.fit(X_remove_top_100,train.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### d. Use only the subject line (see the data) as the feature set. Call this Model5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We need to extract the subject line from each email."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Subject: thank you\\r\\nami and daren , , , ,\\r\\...\n",
       "1    Subject: spot or firm tickets\\r\\nvance ,\\r\\nth...\n",
       "2    Subject: software\\r\\nmicrosoft windows xp prof...\n",
       "3    Subject: noms / actual flow for 2 / 27\\r\\nwe a...\n",
       "4    Subject: superb so . ftware\\r\\nyoull discover ...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.text.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see that the first encounter of the \"\\r\\n\" denotes the end of the Subject line. We just need to filter everything before that out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_subject_line(email):\n",
    "    subject = email.split(\"\\r\\n\")[0]\n",
    "    subject = re.sub(\"Subject: \",'',subject)\n",
    "    return subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['subject_line'] = train['text'].apply(lambda x: extract_subject_line(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                        thank you\n",
       "1             spot or firm tickets\n",
       "2                         software\n",
       "3    noms / actual flow for 2 / 27\n",
       "4               superb so . ftware\n",
       "Name: subject_line, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.subject_line.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_subject = CountVectorizer(analyzer=lambda x:x)\n",
    "X_Subject_Line = cv_subject.fit_transform(train.subject_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model5 = MultinomialNB()\n",
    "Model5.fit(X_Subject_Line,train.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4\n",
    "### 4. Evaluate the performance of the first model and all 4 variations using the validation set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Calculate the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = pd.read_csv(\"./project_1_data/val.csv\")\n",
    "\n",
    "validation['filtered_text'] = validation['text'].apply(lambda x: preprocess(x))\n",
    "validation['subject_line'] = validation['text'].apply(lambda x: extract_subject_line(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaulating Model 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 0.973.\n",
      "The precision score is 0.94.\n",
      "The recall score is 0.966.\n",
      "The f1 score is 0.953.\n"
     ]
    }
   ],
   "source": [
    "X_Validation = cv.transform(validation.filtered_text)\n",
    "\n",
    "Model1_valid_results = Model1.predict(X_Validation)\n",
    "\n",
    "Model1_metrics = get_metrics(Model1_valid_results,validation.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Model 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 0.666.\n",
      "The precision score is 0.553.\n",
      "The recall score is 0.439.\n",
      "The f1 score is 0.49.\n"
     ]
    }
   ],
   "source": [
    "X_Validation_Top_10 = CV_top_10.transform(validation.filtered_text)\n",
    "\n",
    "Model2_valid_results = Model2.predict(X_Validation_Top_10)\n",
    "\n",
    "Model2_metrics = get_metrics(Model2_valid_results,validation.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Model 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 0.851.\n",
      "The precision score is 0.84.\n",
      "The recall score is 0.704.\n",
      "The f1 score is 0.766.\n"
     ]
    }
   ],
   "source": [
    "X_Validation_Top_100 = CV_top_100.transform(validation.filtered_text)\n",
    "\n",
    "Model3_valid_results = Model3.predict(X_Validation_Top_100)\n",
    "\n",
    "Model3_metrics = get_metrics(Model3_valid_results,validation.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Model 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 0.971.\n",
      "The precision score is 0.93.\n",
      "The recall score is 0.969.\n",
      "The f1 score is 0.949.\n"
     ]
    }
   ],
   "source": [
    "X_Validation_Remove_Top_100 = CV.transform(validation.filtered_text)\n",
    "\n",
    "Model4_valid_results = Model4.predict(X_Validation_Remove_Top_100)\n",
    "\n",
    "Model4_metrics = get_metrics(Model4_valid_results,validation.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Model 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 0.688.\n",
      "The precision score is 0.733.\n",
      "The recall score is 0.475.\n",
      "The f1 score is 0.577.\n"
     ]
    }
   ],
   "source": [
    "X_Validation_Subject_Line = cv_subject.transform(validation.subject_line)\n",
    "\n",
    "Model5_valid_results = Model5.predict(X_Validation_Subject_Line)\n",
    "\n",
    "Model5_metrics= get_metrics(Model5_valid_results,validation.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Compare all 5 models\n",
    "#### Summarised Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model1</td>\n",
       "      <td>0.973</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model2</td>\n",
       "      <td>0.666</td>\n",
       "      <td>0.553</td>\n",
       "      <td>0.439</td>\n",
       "      <td>0.490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model3</td>\n",
       "      <td>0.851</td>\n",
       "      <td>0.840</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.766</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model4</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model5</td>\n",
       "      <td>0.688</td>\n",
       "      <td>0.733</td>\n",
       "      <td>0.475</td>\n",
       "      <td>0.577</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Accuracy  Precision  Recall  F1 Score\n",
       "0  Model1     0.973      0.940   0.966     0.953\n",
       "1  Model2     0.666      0.553   0.439     0.490\n",
       "2  Model3     0.851      0.840   0.704     0.766\n",
       "3  Model4     0.971      0.930   0.969     0.949\n",
       "4  Model5     0.688      0.733   0.475     0.577"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_results = pd.DataFrame(columns=['Model','Accuracy','Precision','Recall','F1 Score'])\n",
    "Model1_metrics.insert(0,\"Model1\")\n",
    "Model2_metrics.insert(0,\"Model2\")\n",
    "Model3_metrics.insert(0,\"Model3\")\n",
    "Model4_metrics.insert(0,\"Model4\")\n",
    "Model5_metrics.insert(0,\"Model5\")\n",
    "validation_results.loc[-1] = Model1_metrics\n",
    "validation_results.index = validation_results.index + 1  # shifting index\n",
    "validation_results.loc[-1] = Model2_metrics\n",
    "validation_results.index = validation_results.index + 1  # shifting index\n",
    "validation_results.loc[-1] = Model3_metrics\n",
    "validation_results.index = validation_results.index + 1  # shifting index\n",
    "validation_results.loc[-1] = Model4_metrics\n",
    "validation_results.index = validation_results.index + 1  # shifting index\n",
    "validation_results.loc[-1] = Model5_metrics\n",
    "validation_results.index = validation_results.index + 1  # shifting index\n",
    "validation_results.reset_index(drop = True,inplace=True)\n",
    "validation_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Looking at the performance of all the models, we can see that Model1 and Model4 are the best performers. Since the only difference between these models are the presence of the 100 most frequent words, we can conclude that the 100 most frequent words do not influence the models much since Model4 was trained excluding these words an managed to achieve similar metrics.\n",
    "<hr>\n",
    "- Model2 is the worst performing model. This is due to the fact that we utilised a small subset of 10 features, and coupled with that we utilised the 10 most frequent words as features. If a word is frequently occurring in spam and not spam emails, it is difficult to utilise it to differentiate between spam and not spam emails.\n",
    "<hr>\n",
    "- Model3 was trained on the using the 100 most frequent words as features. Due to the increase in features, the model managed to perform much better than Model2. However since these features are frequent in all emails, the performance of the model is limited. We can also imagine that the increase in performance could be attributed to the words in the top 100 features that have the lowest frequency, since they might produce a greater extent of differentiability between spam and not spam emails.\n",
    "<hr>\n",
    "- Model5 was trained solely utilising the subject line. The model performed relatively poorly since spam emails very seldom include a lot of information in the Subject line that is indicative of it being a spam email. This is due to the fact that if the subject line seems misleading, people would not open them. This can be seen in the cell below where I filtered for spam emails and displayed the extracted Subject lines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3074                        hi , great news ciais viagrra\n",
       "3077                                weekend entertainment\n",
       "3082            save up to 89 % on ink + no shipping cost\n",
       "3083                      get ahead in life with the euro\n",
       "3084    hi paliourg get all pills . everything for you...\n",
       "3088           better pricing means more savings to you .\n",
       "3093                       my site links to your site now\n",
       "3095                  garth howard wanted you to get this\n",
       "3097                                                     \n",
       "3100                                    need legal help ?\n",
       "Name: subject_line, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train['label'] == 1)].subject_line.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c. Make a recommendation about which model to use with reasons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Even though Model1 and Model4 have extremely similar performance in terms of all the metrics, we opt to utilise Model4 as the best model for the following reasons: <br>\n",
    "<ol>\n",
    "    <li> Since the objectective is <strong>spam classifcation</strong> we prefer models that have a lower chance of making a Type 2 error.i.e we do not want to classify an email as not spam when it is an actual fact spam. Consequently we prefer models which provide a higher recall and Model4 has the highest recall.\n",
    "<li> Model4 was also trained without the 100 most frequent words. This ensures that the model is not reliant on these frequent words in order to make any classifications. Consequently, the presence of these frequently used words will have no bearing on the classification of Model4.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5\n",
    "### 5. Now, evaluate all the models with the test set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a. Calculate the evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"./project_1_data/test.csv\")\n",
    "\n",
    "test['filtered_text'] = test['text'].apply(lambda x: preprocess(x))\n",
    "test['subject_line'] = test['text'].apply(lambda x: extract_subject_line(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaulating Model 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 0.969.\n",
      "The precision score is 0.917.\n",
      "The recall score is 0.975.\n",
      "The f1 score is 0.945.\n"
     ]
    }
   ],
   "source": [
    "X_Test = cv.transform(test.filtered_text)\n",
    "\n",
    "Model1_test_results = Model1.predict(X_Test)\n",
    "\n",
    "Model1_test_metrics = get_metrics(Model1_test_results,test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Model 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 0.665.\n",
      "The precision score is 0.573.\n",
      "The recall score is 0.441.\n",
      "The f1 score is 0.499.\n"
     ]
    }
   ],
   "source": [
    "X_Test_Top_10 = CV_top_10.transform(test.filtered_text)\n",
    "\n",
    "Model2_test_results = Model2.predict(X_Test_Top_10)\n",
    "\n",
    "Model2_test_metrics = get_metrics(Model2_test_results,test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Model 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 0.86.\n",
      "The precision score is 0.87.\n",
      "The recall score is 0.711.\n",
      "The f1 score is 0.783.\n"
     ]
    }
   ],
   "source": [
    "X_Test_Top_100 = CV_top_100.transform(test.filtered_text)\n",
    "\n",
    "Model3_test_results = Model3.predict(X_Test_Top_100)\n",
    "\n",
    "Model3_test_metrics = get_metrics(Model3_test_results,test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Model 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 0.971.\n",
      "The precision score is 0.917.\n",
      "The recall score is 0.982.\n",
      "The f1 score is 0.948.\n"
     ]
    }
   ],
   "source": [
    "X_Test_Remove_Top_100 = CV.transform(test.filtered_text)\n",
    "\n",
    "Model4_test_results = Model4.predict(X_Test_Remove_Top_100)\n",
    "\n",
    "Model4_test_metrics = get_metrics(Model4_test_results,test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluating Model 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 0.699.\n",
      "The precision score is 0.773.\n",
      "The recall score is 0.488.\n",
      "The f1 score is 0.599.\n"
     ]
    }
   ],
   "source": [
    "X_Test_Subject_Line = cv_subject.transform(test.subject_line)\n",
    "\n",
    "Model5_test_results = Model5.predict(X_Test_Subject_Line)\n",
    "\n",
    "Model5_test_metrics= get_metrics(Model5_test_results,test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarised Test Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model1</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Model2</td>\n",
       "      <td>0.665</td>\n",
       "      <td>0.573</td>\n",
       "      <td>0.441</td>\n",
       "      <td>0.499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Model3</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.870</td>\n",
       "      <td>0.711</td>\n",
       "      <td>0.783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Model4</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Model5</td>\n",
       "      <td>0.699</td>\n",
       "      <td>0.773</td>\n",
       "      <td>0.488</td>\n",
       "      <td>0.599</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model  Accuracy  Precision  Recall  F1 Score\n",
       "0  Model1     0.969      0.917   0.975     0.945\n",
       "1  Model2     0.665      0.573   0.441     0.499\n",
       "2  Model3     0.860      0.870   0.711     0.783\n",
       "3  Model4     0.971      0.917   0.982     0.948\n",
       "4  Model5     0.699      0.773   0.488     0.599"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = pd.DataFrame(columns=['Model','Accuracy','Precision','Recall','F1 Score'])\n",
    "Model1_test_metrics.insert(0,\"Model1\")\n",
    "Model2_test_metrics.insert(0,\"Model2\")\n",
    "Model3_test_metrics.insert(0,\"Model3\")\n",
    "Model4_test_metrics.insert(0,\"Model4\")\n",
    "Model5_test_metrics.insert(0,\"Model5\")\n",
    "test_results.loc[-1] = Model1_test_metrics\n",
    "test_results.index = test_results.index + 1  # shifting index\n",
    "test_results.loc[-1] = Model2_test_metrics\n",
    "test_results.index = test_results.index + 1  # shifting index\n",
    "test_results.loc[-1] = Model3_test_metrics\n",
    "test_results.index = test_results.index + 1  # shifting index\n",
    "test_results.loc[-1] = Model4_test_metrics\n",
    "test_results.index = test_results.index + 1  # shifting index\n",
    "test_results.loc[-1] = Model5_test_metrics\n",
    "test_results.index = test_results.index + 1  # shifting index\n",
    "test_results.reset_index(drop=True,inplace=True)\n",
    "test_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Is your recommendation (in 4c above) still is valid? Explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Yes, Model4 was still the best performing Model on the test as well. This is due to the fact that the model does not use the frequent words to classify an email. Consequently, the presence or absence of these has no bearing on the performance of the model which increases the models ability to generalise well on unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 6\n",
    "\n",
    "### 6. Implement at least one more variation to improve the performance of the best model. For instance, use frequent n-grams as features. The improvement should be on at least one of the evaluation metrics. Cleary describe the improved model and explain how it is an improvement.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Extracting all the emails that are spam in the training data\n",
    "spam_training_data = train[(train['label'] == 1)]\n",
    "ham_training_data = train[(train['label'] == 0)]\n",
    "\n",
    "spam_vocab = []\n",
    "for spam in spam_training_data.filtered_text:\n",
    "    spam_vocab.extend(spam)\n",
    "\n",
    "ham_vocab = []\n",
    "for ham in ham_training_data.filtered_text:\n",
    "    ham_vocab.extend(ham)\n",
    "    \n",
    "## Creating a vocabulary of all the words used in the spam emails \n",
    "spam_vocab = Counter(spam_vocab)\n",
    "spam_vocab = dict(sorted(spam_vocab.items(), key=lambda item: item[1],reverse=True))\n",
    "\n",
    "## Creating a vocabulary of all the words used in the spam emails \n",
    "ham_vocab = Counter(ham_vocab)\n",
    "ham_vocab = dict(sorted(ham_vocab.items(), key=lambda item: item[1],reverse=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ham_vocab_words = set(ham_vocab.keys())\n",
    "spam_vocab_words = set(spam_vocab.keys())\n",
    "# shared_words = ham_vocab_words.intersection(spam_vocab_words)\n",
    "not_shared_words = ham_vocab_words.difference(spam_vocab_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total number of shared words between Ham and Spam emails is 9416.\n"
     ]
    }
   ],
   "source": [
    "print(f\"The total number of shared words between Ham and Spam emails is {len(not_shared_words)}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can add the words that are unique to ham emails and not included in the current vocabulary to the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Finding the words that belong to Ham emails that are not in the vocab used in Model4\n",
    "new_vocabulary = not_shared_words.difference(set(new_vocab_excluding_top_100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lists merged correctly !\n",
      "The number of new wordsin the vocabulary are 5.\n"
     ]
    }
   ],
   "source": [
    "## Adding the words found above to the vocabulary\n",
    "updated_vocab = new_vocab_excluding_top_100 + list(new_vocabulary)\n",
    "assert(len(updated_vocab) == (len(new_vocab_excluding_top_100) + len(new_vocabulary))),print(\"Incorrect Number of words. Please fix merge\")\n",
    "print(f\"Lists merged correctly !\\nThe number of new wordsin the vocabulary are {len(new_vocabulary)}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct Number of features extracted: Passed !\n"
     ]
    }
   ],
   "source": [
    "CV_Final = CountVectorizer(analyzer = lambda x: x, vocabulary =updated_vocab )\n",
    "X_Final = CV_Final.fit_transform(train.filtered_text)\n",
    "assert(X_Final.toarray().shape[1] == len(updated_vocab)),print(\"Incorrect Number of features extracted\")\n",
    "assert(sorted(CV.get_feature_names_out()) == sorted(list(vocabulary.keys())[100:])),print(\"Incorrect features are being extracted\")\n",
    "print(\"Correct Number of features extracted: Passed !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Model_Final = MultinomialNB()\n",
    "Model_Final.fit(X_Final,train.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating improved model on Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 0.976.\n",
      "The precision score is 0.95.\n",
      "The recall score is 0.966.\n",
      "The f1 score is 0.958.\n"
     ]
    }
   ],
   "source": [
    "X_Validation_Final= CV_Final.transform(validation.filtered_text)\n",
    "\n",
    "Model_Final_valid_results = Model_Final.predict(X_Validation_Final)\n",
    "\n",
    "Model_Final_metrics = get_metrics(Model_Final_valid_results,validation.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing validation metrics for the impoved model and model 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model4</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.969</td>\n",
       "      <td>0.949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Improved Model</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.958</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Accuracy  Precision  Recall    F1 \n",
       "0          Model4     0.971       0.93   0.969  0.949\n",
       "1  Improved Model     0.976       0.95   0.966  0.958"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improved_valid = pd.DataFrame(columns = [\"Model\",\"Accuracy\",\"Precision\",\"Recall\",'F1 '])\n",
    "Model_Final_metrics.insert(0,\"Improved Model\")\n",
    "\n",
    "improved_valid.loc[-1] = Model4_metrics\n",
    "improved_valid.index = improved_valid.index + 1  # shifting index\n",
    "\n",
    "improved_valid.loc[-1] = Model_Final_metrics\n",
    "improved_valid.index = improved_valid.index + 1  # shifting index\n",
    "\n",
    "improved_valid.reset_index(drop=True,inplace=True)\n",
    "\n",
    "improved_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating improved Model on Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score is 0.976.\n",
      "The precision score is 0.933.\n",
      "The recall score is 0.982.\n",
      "The f1 score is 0.957.\n"
     ]
    }
   ],
   "source": [
    "X_Test_Final= CV_Final.transform(test.filtered_text)\n",
    "\n",
    "Model_Final_Test_results = Model_Final.predict(X_Test_Final)\n",
    "\n",
    "Model_Final_Test_metrics = get_metrics(Model_Final_Test_results,test.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing test metrics for the impoved model and model 4.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Model4</td>\n",
       "      <td>0.971</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Improved Model</td>\n",
       "      <td>0.976</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.982</td>\n",
       "      <td>0.957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Model  Accuracy  Precision  Recall    F1 \n",
       "0          Model4     0.971      0.917   0.982  0.948\n",
       "1  Improved Model     0.976      0.933   0.982  0.957"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "improved_test = pd.DataFrame(columns = [\"Model\",\"Accuracy\",\"Precision\",\"Recall\",'F1 '])\n",
    "Model_Final_Test_metrics.insert(0,\"Improved Model\")\n",
    "\n",
    "improved_test.loc[-1] = Model4_test_metrics\n",
    "improved_test.index = improved_test.index + 1  # shifting index\n",
    "\n",
    "improved_test.loc[-1] = Model_Final_Test_metrics\n",
    "improved_test.index = improved_test.index + 1  # shifting index\n",
    "\n",
    "improved_test.reset_index(drop=True,inplace=True)\n",
    "\n",
    "improved_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The improvement made to the feature set was based on the vocabulary.\n",
    "- In order to improve the models ability at detecting Ham/Non-spam emails, we found the words that were **uniquely** in Ham emails and were not in the vocabulary initially used for Model4. We emphasize uniquely since these words **DO NOT** occur in spam emails.\n",
    "- By adding these unique words, they become greater differentiatiors between ham and spam emails. Since these words indicate ham emails, the models ability to reduce the amount of False Positives is increased since it is better at detecting Ham emails. Since the total number of False Positives are decreased, the model achieves a better **Precision** which indirectly increases the accuracy as well.\n",
    "- The afore mentioned increase in **Precision** and **Accuracy** is achieved on both, the validation and test set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "d2af9183f1518e5b7e9d321053af756667ae69187df0ee0edf15440703f50b25"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
